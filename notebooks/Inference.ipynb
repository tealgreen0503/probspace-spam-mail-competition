{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1IDRwhXUg64w_3Tw5l7z9Nzzw0seDTzu3","authorship_tag":"ABX9TyN2Xhh6tGZIhJw5A514XEs4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zsUd_-hBNVxC"},"source":["!pip install transformers nlp\n","!pip install pulp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBTwln-QSWHl"},"source":["%cd \"/content/drive/My Drive/Colab Notebooks/Competition/ProbSpace/Spam mail\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmcdGTR8YqBB"},"source":["import collections\n","import os\n","import random\n","import re\n","import time\n","\n","from bs4 import BeautifulSoup\n","import numpy as np\n","import pandas as pd\n","import plotly.express as px\n","import pulp\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report, f1_score, confusion_matrix\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm.notebook import tqdm\n","\n","from transformers import (\n","    AutoConfig,\n","    AutoTokenizer,\n","    AutoModel,\n","    AdamW,\n","    get_cosine_schedule_with_warmup\n",")\n","import nlp\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hWyfEKHY1oV"},"source":["SEED = 42\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        \n","seed_everything(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1S3c_fNY-tx"},"source":["if torch.cuda.is_available():\n","    current_device = torch.cuda.current_device()\n","    print(\"Device:\", torch.cuda.get_device_name(current_device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qRUpFQuZBlq"},"source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","TRAIN_FILE = \"./data/train_data.csv\"\n","TEST_FILE = \"./data/test_data.csv\"\n","MODEL_PATHS = ['./checkpoint/bert-base-uncased-baseline/',\n","               './checkpoint/roberta-base-baseline/',\n","               './checkpoint/google_electra-base-discriminator-baseline/',\n","               './checkpoint/bert-base-uncased-custom-tokenizer/',\n","               './checkpoint/roberta-base-custom-tokenizer/',\n","               './checkpoint/google_electra-base-discriminator-custom-tokenizer/']\n","MODEL_NAMES = ['bert-base-uncased',\n","               'roberta-base',\n","               'google/electra-base-discriminator',\n","               'bert-base-uncased',\n","               'roberta-base',\n","               'google/electra-base-discriminator']\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 128\n","NUM_CLASSES = 2\n","EPOCHS = 10\n","NUM_SPLITS = 5\n","TEST_FREQS = [7838, 17000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"333P4OfXNpJx"},"source":["def make_dataset(df, tokenizer, device):\n","    dataset = nlp.Dataset.from_pandas(df)\n","    dataset = dataset.map(lambda example: tokenizer(example[\"contents\"]))\n","    if 'token_type_ids' not in dataset.features:\n","        dataset.set_format(type='torch', \n","                           columns=['input_ids', 'attention_mask'], \n","                           device=device)\n","    else:\n","        dataset.set_format(type='torch', \n","                           columns=['input_ids', 'token_type_ids', 'attention_mask'], \n","                           device=device)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsKeBGQKBil8"},"source":["class Tokenizer:\n","    def __init__(self, model_name, additional_tokens=None, max_length=512):\n","        self.bert_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","        self.bert_tokenizer.add_tokens(additional_tokens)\n","        self.max_length = max_length\n","        assert self.max_length % 2 == 0\n","\n","    def __call__(self, text):\n","        sep_index = text.find(\"\\r\\n\")\n","        input = self.bert_tokenizer(text[:sep_index], text[sep_index:],\n","                                    padding='max_length', max_length=self.max_length)\n","        if len(input[\"input_ids\"]) > self.max_length:\n","            for k, v in input.items():\n","                input[k] = v[:self.max_length//4] + v[-(self.max_length//4)*3:]\n","        return input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19n2KCFN5wv4"},"source":["class Classifier(nn.Module):\n","    def __init__(self, model_name, num_classes=2):\n","        super().__init__()\n","\n","        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n","        self.bert = AutoModel.from_config(config=self.config)\n","        self.dropout = nn.Dropout(0.2)\n","        n_weights = self.config.num_hidden_layers + 1\n","        weights_init = torch.zeros(n_weights).float()\n","        weights_init.data[:-1] = -3\n","        self.layer_weights = torch.nn.Parameter(weights_init)\n","        self.high_dropout = nn.Dropout(p=0.5)\n","        self.linear = nn.Linear(self.config.hidden_size, num_classes)\n","        \n","        nn.init.normal_(self.linear.weight, mean=0.0, std=self.config.initializer_range)\n","        nn.init.zeros_(self.linear.bias)\n","\n","    def forward(self, **inputs):\n","        outputs = self.bert(**inputs)\n","        hidden_layers = outputs.hidden_states\n","        \n","        if not(hasattr(self.config, 'summary_type')) or self.config.summary_type == 'first':\n","            output = torch.stack(\n","                [self.dropout(layer[:, 0, :]) for layer in hidden_layers], dim=2\n","            )\n","        elif self.config.summary_type == 'last':\n","            output = torch.stack(\n","                [self.dropout(layer[:, -1, :]) for layer in hidden_layers], dim=2\n","            )\n","        else:\n","            raise Exception('invalid summary_type') \n","\n","        output = (torch.softmax(self.layer_weights, dim=0) * output).sum(-1)\n","        \n","        output = torch.mean(\n","            torch.stack(\n","                [self.linear(self.high_dropout(output)) for _ in range(5)],\n","                dim=0,\n","            ),\n","            dim=0,\n","        )\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvHkVcTvHgzU"},"source":["def get_models(model_name, model_path, tokenizer, num_splits=5):\n","    models = []\n","    for fold in tqdm(range(num_splits)):\n","        model = Classifier(model_name, NUM_CLASSES)\n","        if \"custom-tokenizer\" in model_path:\n","            model.bert.resize_token_embeddings(len(tokenizer.bert_tokenizer))\n","        model.load_state_dict(torch.load(model_path + f\"{model_name.replace('/', '_')}_{fold}.pth\"))\n","        model.to(DEVICE)\n","        model.eval()\n","        models.append(model)\n","    return models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gWhqUg93y-r"},"source":["# 制約付き対数尤度最大化問題を解く\n","def hack(prob):\n","    logp = np.log(prob + 1e-16)\n","    N = prob.shape[0]\n","    K = prob.shape[1]\n","\n","    m = pulp.LpProblem('Problem', pulp.LpMaximize)  # 最大化問題\n","\n","    # 最適化する変数(= 提出ラベル)\n","    x = pulp.LpVariable.dicts('x', [(i, j) for i in range(N) for j in range(K)], 0, 1, pulp.LpBinary)\n","    \n","    # log likelihood(目的関数)\n","    log_likelihood = pulp.lpSum([x[(i, j)] * logp[i, j] for i in range(N) for j in range(K)])\n","    m += log_likelihood\n","    \n","    # 各データについて，1クラスだけを予測ラベルとする制約\n","    for i in range(N):\n","        m += pulp.lpSum([x[(i, k)] for k in range(K)]) == 1  # i.e., SOS1\n","    \n","    # 各クラスについて，推定個数の合計に関する制約\n","    for k in range(K):\n","        m += pulp.lpSum([x[(i, k)] for i in range(N)]) == TEST_FREQS[k]\n","        \n","    m.solve()  # 解く\n","\n","    assert m.status == 1  # assert 最適 <=>（実行可能解が見つからないとエラー）\n","\n","    x_ast = np.array([[int(x[(i, j)].value()) for j in range(K)] for i in range(N)])  # 結果の取得\n","    return x_ast.argmax(axis=1) # 結果をonehotから -> {0, 1}のラベルに変換"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0mi745iXhLF"},"source":["def postprocess(final_output, test_df):\n","    assert final_output.shape[0] == test_df.shape[0]\n","    is_empty = test_df['contents'] == 'Subject: \\r\\n'\n","    final_output[is_empty] = np.array([0.0, 1.0])\n","    return final_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qs1BNn1SyYPW"},"source":["test_df = pd.read_csv(TEST_FILE)\n","\n","with torch.no_grad():\n","    final_output = np.empty([0])\n","\n","    for model_name, model_path in tqdm(zip(MODEL_NAMES, MODEL_PATHS), total=len(MODEL_PATHS)):\n","        if \"custom-tokenizer\" in model_path:\n","            additional_tokens = [' enron ', ' ect ', ' hou ']\n","            tokenizer = Tokenizer(model_name, additional_tokens)\n","        else:\n","            tokenizer = Tokenizer(model_name)\n","        models = get_models(model_name, model_path, tokenizer)\n","        dataset = make_dataset(test_df, tokenizer, DEVICE)\n","        test_dataloader = torch.utils.data.DataLoader(\n","            dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n","        \n","        for model in tqdm(models, total=len(models)):\n","            for inputs in test_dataloader:\n","                output = model(**inputs)\n","                output = output.cpu().detach().numpy()\n","                final_output = np.append(final_output, output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6reMsS7Tx6OU"},"source":["final_output = final_output.reshape(-1, len(test_dataloader.dataset), NUM_CLASSES)\n","assert final_output.shape[0] == len(MODEL_NAMES) * NUM_SPLITS\n","final_output = np.mean(final_output, axis=0)\n","final_output = torch.from_numpy(final_output.astype(np.float32))\n","final_output = torch.softmax(final_output, dim=1).cpu().detach().numpy()\n","\n","final_output = postprocess(final_output, test_df)\n","final_output = hack(final_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxaZS7P6VJVw"},"source":["submit = pd.DataFrame(columns=['id', 'y'])\n","submit['id'] = range(1, 24838+1)\n","submit['y'] = final_output\n","submit.to_csv(\"./output/submission_ensemble.csv\", index=False)\n","submit.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I58p8ZqhIc_p"},"source":["fig = px.pie(submit, names='y')\n","fig.show()"],"execution_count":null,"outputs":[]}]}